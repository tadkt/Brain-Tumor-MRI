{"cells":[{"cell_type":"code","execution_count":26,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-10T15:15:57.533585Z","iopub.status.busy":"2024-09-10T15:15:57.532657Z","iopub.status.idle":"2024-09-10T15:15:57.544897Z","shell.execute_reply":"2024-09-10T15:15:57.543965Z","shell.execute_reply.started":"2024-09-10T15:15:57.533542Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["An error occurred: [Errno 17] File exists: '/kaggle/working/mri/'\n","An error occurred: [Errno 17] File exists: '/kaggle/working/ct/'\n"]}],"source":["import torch\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","import os\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","TRAIN_DIR = \"/kaggle/input/ct-to-mri-cgan/Dataset/images\"\n","VAL_DIR = \"/kaggle/input/ct-to-mri-cgan/Dataset/unseen_demo_images\"\n","BATCH_SIZE = 1\n","LEARNING_RATE = 1e-5\n","LAMBDA_IDENTITY = 0.0\n","LAMBDA_CYCLE = 10\n","NUM_WORKERS = 1\n","NUM_EPOCHS = 10\n","LOAD_MODEL = False\n","SAVE_MODEL = True\n","CHECKPOINT_GEN_H = \"genh.pth.tar\"\n","CHECKPOINT_GEN_Z = \"genz.pth.tar\"\n","CHECKPOINT_CRITIC_H = \"critich.pth.tar\"\n","CHECKPOINT_CRITIC_Z = \"criticz.pth.tar\"\n","directory_name = \"/kaggle/working/mri/\"\n","\n","# Create the directory\n","try:\n","    os.makedirs(directory_name)\n","    print(f\"Directory '{directory_name}' created successfully.\")\n","except Exception as e:\n","    print(f\"An error occurred: {e}\")\n","try:\n","    os.makedirs(\"/kaggle/working/ct/\")\n","    print(f\"Directory '{directory_name}' created successfully.\")\n","except Exception as e:\n","    print(f\"An error occurred: {e}\") \n","transforms = A.Compose(\n","    [\n","        A.Resize(width=256, height=256),\n","        A.HorizontalFlip(p=0.5),\n","        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255),\n","        ToTensorV2(),\n","    ],\n","    additional_targets={\"image0\": \"image\"},is_check_shapes = False,\n",")"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T15:15:57.546900Z","iopub.status.busy":"2024-09-10T15:15:57.546579Z","iopub.status.idle":"2024-09-10T15:15:57.775313Z","shell.execute_reply":"2024-09-10T15:15:57.773973Z","shell.execute_reply.started":"2024-09-10T15:15:57.546866Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([2, 3, 256, 256])\n"]}],"source":["\"\"\"\n","Generator model for CycleGAN\n","\n","Programmed by Aladdin Persson <aladdin.persson at hotmail dot com>\n","* 2020-11-05: Initial coding\n","* 2022-12-21: Small revision of code, checked that it works with latest PyTorch version\n","\"\"\"\n","\n","import torch\n","import torch.nn as nn\n","\n","\n","class ConvBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, down=True, use_act=True, **kwargs):\n","        super().__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, padding_mode=\"reflect\", **kwargs)\n","            if down\n","            else nn.ConvTranspose2d(in_channels, out_channels, **kwargs),\n","            nn.InstanceNorm2d(out_channels),\n","            nn.ReLU(inplace=True) if use_act else nn.Identity(),\n","        )\n","\n","    def forward(self, x):\n","        return self.conv(x)\n","\n","\n","class ResidualBlock(nn.Module):\n","    def __init__(self, channels):\n","        super().__init__()\n","        self.block = nn.Sequential(\n","            ConvBlock(channels, channels, kernel_size=3, padding=1),\n","            ConvBlock(channels, channels, use_act=False, kernel_size=3, padding=1),\n","        )\n","\n","    def forward(self, x):\n","        return x + self.block(x)\n","\n","\n","class Generator(nn.Module):\n","    def __init__(self, img_channels, num_features=64, num_residuals=9):\n","        super().__init__()\n","        self.initial = nn.Sequential(\n","            nn.Conv2d(\n","                img_channels,\n","                num_features,\n","                kernel_size=7,\n","                stride=1,\n","                padding=3,\n","                padding_mode=\"reflect\",\n","            ),\n","            nn.InstanceNorm2d(num_features),\n","            nn.ReLU(inplace=True),\n","        )\n","        self.down_blocks = nn.ModuleList(\n","            [\n","                ConvBlock(\n","                    num_features, num_features * 2, kernel_size=3, stride=2, padding=1\n","                ),\n","                ConvBlock(\n","                    num_features * 2,\n","                    num_features * 4,\n","                    kernel_size=3,\n","                    stride=2,\n","                    padding=1,\n","                ),\n","            ]\n","        )\n","        self.res_blocks = nn.Sequential(\n","            *[ResidualBlock(num_features * 4) for _ in range(num_residuals)]\n","        )\n","        self.up_blocks = nn.ModuleList(\n","            [\n","                ConvBlock(\n","                    num_features * 4,\n","                    num_features * 2,\n","                    down=False,\n","                    kernel_size=3,\n","                    stride=2,\n","                    padding=1,\n","                    output_padding=1,\n","                ),\n","                ConvBlock(\n","                    num_features * 2,\n","                    num_features * 1,\n","                    down=False,\n","                    kernel_size=3,\n","                    stride=2,\n","                    padding=1,\n","                    output_padding=1,\n","                ),\n","            ]\n","        )\n","\n","        self.last = nn.Conv2d(\n","            num_features * 1,\n","            img_channels,\n","            kernel_size=7,\n","            stride=1,\n","            padding=3,\n","            padding_mode=\"reflect\",\n","        )\n","\n","    def forward(self, x):\n","        x = self.initial(x)\n","        for layer in self.down_blocks:\n","            x = layer(x)\n","        x = self.res_blocks(x)\n","        for layer in self.up_blocks:\n","            x = layer(x)\n","        return torch.tanh(self.last(x))\n","\n","\n","def test():\n","    img_channels = 3\n","    img_size = 256\n","    x = torch.randn((2, img_channels, img_size, img_size))\n","    gen = Generator(img_channels, 9)\n","    print(gen(x).shape)\n","\n","\n","if __name__ == \"__main__\":\n","    test()"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T15:15:57.777311Z","iopub.status.busy":"2024-09-10T15:15:57.776964Z","iopub.status.idle":"2024-09-10T15:15:58.047710Z","shell.execute_reply":"2024-09-10T15:15:58.046673Z","shell.execute_reply.started":"2024-09-10T15:15:57.777256Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([5, 1, 30, 30])\n"]}],"source":["\"\"\"\n","Discriminator model for CycleGAN\n","\n","Programmed by Aladdin Persson <aladdin.persson at hotmail dot com>\n","* 2020-11-05: Initial coding\n","* 2022-12-21: Small revision of code, checked that it works with latest PyTorch version\n","\"\"\"\n","\n","import torch\n","import torch.nn as nn\n","\n","\n","class Block(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride):\n","        super().__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels,\n","                out_channels,\n","                4,\n","                stride,\n","                1,\n","                bias=True,\n","                padding_mode=\"reflect\",\n","            ),\n","            nn.InstanceNorm2d(out_channels),\n","            nn.LeakyReLU(0.2, inplace=True),\n","        )\n","\n","    def forward(self, x):\n","        return self.conv(x)\n","\n","\n","class Discriminator(nn.Module):\n","    def __init__(self, in_channels=3, features=[64, 128, 256, 512]):\n","        super().__init__()\n","        self.initial = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels,\n","                features[0],\n","                kernel_size=4,\n","                stride=2,\n","                padding=1,\n","                padding_mode=\"reflect\",\n","            ),\n","            nn.LeakyReLU(0.2, inplace=True),\n","        )\n","\n","        layers = []\n","        in_channels = features[0]\n","        for feature in features[1:]:\n","            layers.append(\n","                Block(in_channels, feature, stride=1 if feature == features[-1] else 2)\n","            )\n","            in_channels = feature\n","        layers.append(\n","            nn.Conv2d(\n","                in_channels,\n","                1,\n","                kernel_size=4,\n","                stride=1,\n","                padding=1,\n","                padding_mode=\"reflect\",\n","            )\n","        )\n","        self.model = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.initial(x)\n","        return torch.sigmoid(self.model(x))\n","\n","\n","def test():\n","    x = torch.randn((5, 3, 256, 256))\n","    model = Discriminator(in_channels=3)\n","    preds = model(x)\n","    print(preds.shape)\n","\n","\n","if __name__ == \"__main__\":\n","    test()"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T15:15:58.051112Z","iopub.status.busy":"2024-09-10T15:15:58.050687Z","iopub.status.idle":"2024-09-10T15:15:58.061927Z","shell.execute_reply":"2024-09-10T15:15:58.060757Z","shell.execute_reply.started":"2024-09-10T15:15:58.051057Z"},"trusted":true},"outputs":[],"source":["from PIL import Image\n","import os\n","from torch.utils.data import Dataset\n","import numpy as np\n","\n","class MRI_CT_dataset(Dataset):\n","    def __init__(self, root_ct, root_mri, transform=None):\n","        self.root_ct = root_ct\n","        self.root_mri = root_mri\n","        self.transform = transform\n","\n","        self.ct_images = os.listdir(root_ct)\n","        self.mri_images = os.listdir(root_mri)\n","        self.length_dataset = max(len(self.ct_images), len(self.mri_images)) # 1000, 1500\n","        self.ct_len = len(self.ct_images)\n","        self.mri_len = len(self.mri_images)\n","\n","    def __len__(self):\n","        return self.length_dataset\n","\n","    def __getitem__(self, index):\n","        ct_img = self.ct_images[index % self.ct_len]\n","        mri_img = self.mri_images[index % self.mri_len]\n","\n","        ct_path = os.path.join(self.root_ct, ct_img)\n","        mri_path = os.path.join(self.root_mri, mri_img)\n","\n","        ct_img = np.array(Image.open(ct_path).convert(\"L\"))\n","        mri_img = np.array(Image.open(mri_path).convert(\"L\"))\n","\n","        if self.transform:\n","            augmentations = self.transform(image=ct_img, image0=mri_img)\n","            ct_img = augmentations[\"image\"]\n","            mri_img = augmentations[\"image0\"]\n","\n","        return ct_img, mri_img"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T15:15:58.064012Z","iopub.status.busy":"2024-09-10T15:15:58.063598Z","iopub.status.idle":"2024-09-10T15:16:10.815408Z","shell.execute_reply":"2024-09-10T15:16:10.814044Z","shell.execute_reply.started":"2024-09-10T15:15:58.063969Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: config in /opt/conda/lib/python3.10/site-packages (0.5.1)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install config"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T15:16:10.817235Z","iopub.status.busy":"2024-09-10T15:16:10.816922Z","iopub.status.idle":"2024-09-10T15:16:10.827741Z","shell.execute_reply":"2024-09-10T15:16:10.826879Z","shell.execute_reply.started":"2024-09-10T15:16:10.817201Z"},"trusted":true},"outputs":[],"source":["import random, torch, os, numpy as np\n","import torch.nn as nn\n","import config\n","import copy\n","\n","def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n","    print(\"=> Saving checkpoint\")\n","    checkpoint = {\n","        \"state_dict\": model.state_dict(),\n","        \"optimizer\": optimizer.state_dict(),\n","    }\n","    torch.save(checkpoint, filename)\n","\n","\n","def load_checkpoint(checkpoint_file, model, optimizer, lr):\n","    print(\"=> Loading checkpoint\")\n","    checkpoint = torch.load(checkpoint_file, map_location=DEVICE)\n","    model.load_state_dict(checkpoint[\"state_dict\"])\n","    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n","\n","    # If we don't do this then it will just have learning rate of old checkpoint\n","    # and it will lead to many hours of debugging \\:\n","    for param_group in optimizer.param_groups:\n","        param_group[\"lr\"] = lr\n","\n","\n","def seed_everything(seed=42):\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-10T15:16:10.829438Z","iopub.status.busy":"2024-09-10T15:16:10.829170Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_36/1337225219.py:167: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  g_scaler = torch.cuda.amp.GradScaler()\n","/tmp/ipykernel_36/1337225219.py:168: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  d_scaler = torch.cuda.amp.GradScaler()\n","  0%|          | 0/1744 [00:00<?, ?it/s]/tmp/ipykernel_36/1337225219.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast():\n","/tmp/ipykernel_36/1337225219.py:57: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast():\n","100%|██████████| 1744/1744 [09:46<00:00,  2.97it/s, H_fake=0.401, H_real=0.594]\n"]},{"name":"stdout","output_type":"stream","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","=> Saving checkpoint\n","=> Saving checkpoint\n"]},{"name":"stderr","output_type":"stream","text":[" 24%|██▎       | 414/1744 [02:19<07:27,  2.98it/s, H_fake=0.374, H_real=0.615]"]}],"source":["\"\"\"\n","Training for CycleGAN\n","\n","Programmed by Aladdin Persson <aladdin.persson at hotmail dot com>\n","* 2020-11-05: Initial coding\n","* 2022-12-21: Small revision of code, checked that it works with latest PyTorch version\n","\"\"\"\n","\n","import torch\n","import sys\n","from torch.utils.data import DataLoader\n","import torch.nn as nn\n","import torch.optim as optim\n","import config\n","from tqdm import tqdm\n","from torchvision.utils import save_image\n","\n","\n","def train_fn(\n","    disc_H, disc_Z, gen_Z, gen_H, loader, opt_disc, opt_gen, l1, mse, d_scaler, g_scaler\n","):\n","    H_reals = 0\n","    H_fakes = 0\n","    loop = tqdm(loader, leave=True)\n","\n","    for idx, (ct, mri) in enumerate(loop):\n","        ct = ct.to(DEVICE)\n","        mri = mri.to(DEVICE)\n","\n","        # Train Discriminators H and Z\n","        with torch.cuda.amp.autocast():\n","            fake_mri = gen_H(ct)\n","            D_H_real = disc_H(mri)\n","            D_H_fake = disc_H(fake_mri.detach())\n","            H_reals += D_H_real.mean().item()\n","            H_fakes += D_H_fake.mean().item()\n","            D_H_real_loss = mse(D_H_real, torch.ones_like(D_H_real))\n","            D_H_fake_loss = mse(D_H_fake, torch.zeros_like(D_H_fake))\n","            D_H_loss = D_H_real_loss + D_H_fake_loss\n","\n","            fake_ct = gen_Z(mri)\n","            D_Z_real = disc_Z(ct)\n","            D_Z_fake = disc_Z(fake_ct.detach())\n","            D_Z_real_loss = mse(D_Z_real, torch.ones_like(D_Z_real))\n","            D_Z_fake_loss = mse(D_Z_fake, torch.zeros_like(D_Z_fake))\n","            D_Z_loss = D_Z_real_loss + D_Z_fake_loss\n","\n","            # put it togethor\n","            D_loss = (D_H_loss + D_Z_loss) / 2\n","\n","        opt_disc.zero_grad()\n","        d_scaler.scale(D_loss).backward()\n","        d_scaler.step(opt_disc)\n","        d_scaler.update()\n","\n","        # Train Generators H and Z\n","        with torch.cuda.amp.autocast():\n","            # adversarial loss for both generators\n","            D_H_fake = disc_H(fake_mri)\n","            D_Z_fake = disc_Z(fake_ct)\n","            loss_G_H = mse(D_H_fake, torch.ones_like(D_H_fake))\n","            loss_G_Z = mse(D_Z_fake, torch.ones_like(D_Z_fake))\n","\n","            # cycle loss\n","            cycle_ct = gen_Z(fake_mri)\n","            cycle_mri = gen_H(fake_ct)\n","            cycle_ct_loss = l1(ct, cycle_ct)\n","            cycle_mri_loss = l1(mri, cycle_mri)\n","\n","            # identity loss (remove these for efficiency if you set lambda_identity=0)\n","            identity_ct = gen_Z(ct)\n","            identity_mri = gen_H(mri)\n","            identity_ct_loss = l1(ct, identity_ct)\n","            identity_mri_loss = l1(mri, identity_mri)\n","\n","            # add all togethor\n","            G_loss = (\n","                loss_G_Z\n","                + loss_G_H\n","                + cycle_ct_loss * LAMBDA_CYCLE\n","                + cycle_mri_loss * LAMBDA_CYCLE\n","                + identity_mri_loss * LAMBDA_IDENTITY\n","                + identity_ct_loss * LAMBDA_IDENTITY\n","            )\n","\n","        opt_gen.zero_grad()\n","        g_scaler.scale(G_loss).backward()\n","        g_scaler.step(opt_gen)\n","        g_scaler.update()\n","\n","        if idx % 200 == 0:\n","            save_image(fake_mri * 0.5 + 0.5, f\"/kaggle/working/mri/mri_{idx}.png\")\n","            save_image(fake_ct * 0.5 + 0.5, f\"/kaggle/working/ct/ct_{idx}.png\")\n","\n","        loop.set_postfix(H_real=H_reals / (idx + 1), H_fake=H_fakes / (idx + 1))\n","\n","\n","def main():\n","    disc_H = Discriminator(in_channels=1).to(DEVICE)\n","    disc_Z = Discriminator(in_channels=1).to(DEVICE)\n","    gen_Z = Generator(img_channels=1, num_residuals=9).to(DEVICE)\n","    gen_H = Generator(img_channels=1, num_residuals=9).to(DEVICE)\n","    opt_disc = optim.Adam(\n","        list(disc_H.parameters()) + list(disc_Z.parameters()),\n","        lr=LEARNING_RATE,\n","        betas=(0.5, 0.999),\n","    )\n","\n","    opt_gen = optim.Adam(\n","        list(gen_Z.parameters()) + list(gen_H.parameters()),\n","        lr=LEARNING_RATE,\n","        betas=(0.5, 0.999),\n","    )\n","\n","    L1 = nn.L1Loss()\n","    mse = nn.MSELoss()\n","\n","    if LOAD_MODEL:\n","        load_checkpoint(\n","            CHECKPOINT_GEN_H,\n","            gen_H,\n","            opt_gen,\n","            LEARNING_RATE,\n","        )\n","        load_checkpoint(\n","            CHECKPOINT_GEN_Z,\n","            gen_Z,\n","            opt_gen,\n","            LEARNING_RATE,\n","        )\n","        load_checkpoint(\n","            CHECKPOINT_CRITIC_H,\n","            disc_H,\n","            opt_disc,\n","            LEARNING_RATE,\n","        )\n","        load_checkpoint(\n","            CHECKPOINT_CRITIC_Z,\n","            disc_Z,\n","            opt_disc,\n","            LEARNING_RATE,\n","        )\n","\n","    dataset = MRI_CT_dataset(\n","        root_ct=TRAIN_DIR + \"/trainA\",\n","        root_mri=TRAIN_DIR + \"/trainB\",\n","        transform=transforms,\n","    )\n","    val_dataset = MRI_CT_dataset(\n","        root_ct=\"/kaggle/input/ct-to-mri-cgan/Dataset/images/testA\",\n","        root_mri=\"/kaggle/input/ct-to-mri-cgan/Dataset/images/testB\",\n","        transform=transforms,\n","    )\n","    val_loader = DataLoader(\n","        val_dataset,\n","        batch_size=1,\n","        shuffle=False,\n","        pin_memory=True,\n","    )\n","    loader = DataLoader(\n","        dataset,\n","        batch_size=BATCH_SIZE,\n","        shuffle=True,\n","        num_workers=NUM_WORKERS,\n","        pin_memory=True,\n","    )\n","    g_scaler = torch.cuda.amp.GradScaler()\n","    d_scaler = torch.cuda.amp.GradScaler()\n","\n","    for epoch in range(NUM_EPOCHS):\n","        train_fn(\n","            disc_H,\n","            disc_Z,\n","            gen_Z,\n","            gen_H,\n","            loader,\n","            opt_disc,\n","            opt_gen,\n","            L1,\n","            mse,\n","            d_scaler,\n","            g_scaler,\n","        )\n","\n","        if SAVE_MODEL:\n","            save_checkpoint(gen_H, opt_gen, filename=CHECKPOINT_GEN_H)\n","            save_checkpoint(gen_Z, opt_gen, filename=CHECKPOINT_GEN_Z)\n","            save_checkpoint(disc_H, opt_disc, filename=CHECKPOINT_CRITIC_H)\n","            save_checkpoint(disc_Z, opt_disc, filename=CHECKPOINT_CRITIC_Z)\n","\n","\n","if __name__ == \"__main__\":\n","    main()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":1322457,"sourceId":2222626,"sourceType":"datasetVersion"}],"dockerImageVersionId":30761,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
